# -*- coding: utf-8 -*-
"""ML One Week Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11td6OqS0FEaM6oY9oQ9OHvR0zRw7Kml7
"""

#Import modul
import numpy as np
import pandas as pd
import statsmodels
import patsy
import statsmodels.api as sm
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder

#import model
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn import metrics

import warnings
warnings.filterwarnings("ignore")



#baca data
df = pd.read_csv('customer_behaviour.csv')
df.head()

df.info()

df.columns

df['City'].unique()

df['Membership Type'].unique()

df['Average Rating'].unique()

df['Discount Applied'].unique()

df['Satisfaction Level'].unique()

df.duplicated().sum()

df['Customer ID'].duplicated().sum()

df.isna().sum()

#Mengisi nilai kosong pada Satisfaction Level dengan Modus
modus_value = df['Satisfaction Level'].mode()[0]  # Mengambil nilai modus
df['Satisfaction Level'].fillna(modus_value, inplace=True)  # Mengisi nilai kosong dengan modus

df.isna().sum()

df['Spend per Item'] = df['Total Spend'] / df['Items Purchased']
# Untuk lebih mengetahui lebih baik
# hubungan antara variabel independen dan kepuasan pelanggan,
#coba hitung Spend per Item dan menambahkannya sebagai kolom baru di dataframe

df.head()

#Download file bersihnya (non encoding) untuk Looker
from google.colab import files
df.to_csv('cleaned_customerbehaviour.csv', index=False)
files.download('cleaned_customerbehaviour.csv')

# Initialize LabelEncoders
le_gender = LabelEncoder()
le_membership = LabelEncoder()
le_discount = LabelEncoder()
le_satisfaction = LabelEncoder()

# Encode the columns
df['Gender'] = le_gender.fit_transform(df['Gender'])
df['Membership Type'] = le_membership.fit_transform(df['Membership Type'])
df['Discount Applied'] = le_discount.fit_transform(df['Discount Applied'])
df['Satisfaction Level'] = le_satisfaction.fit_transform(df['Satisfaction Level'])

df.head()

df.info()

#Download file bersihnya (encoding)
from google.colab import files
df.to_csv('cleanedencode_customerbehaviour.csv', index=False)
files.download('cleanedencode_customerbehaviour.csv')

"""# Uji Normalitas, Detect Outlier, Delete Ooutlier"""

import matplotlib.pyplot as plt

# Misal data kamu ada di dataframe df
features = ['Age', 'Total Spend', 'Items Purchased', 'Average Rating', 'Discount Applied', 'Days Since Last Purchase']

for feature in features:
    plt.figure(figsize=(8, 6))
    plt.scatter(df[feature], df['Satisfaction Level'])
    plt.title(f'{feature} vs Satisfaction Level')
    plt.xlabel(feature)
    plt.ylabel('Satisfaction Level')
    plt.show()

#Distribusi data tidak normal, maka akan menggunakan model Logistic Regression, Decision Tree, atau Random Forest.
#tetap hapus dulu outliernya

#Age
sns.boxplot(df['Age'])
#bagus, tidak ada outlier

sns.boxplot(df['Total Spend'])
#bagus juga

sns.boxplot(df['Items Purchased'])
#bagus

sns.boxplot(df['Average Rating'])
#bagus

sns.boxplot(df['Discount Applied'])

sns.boxplot(df['Days Since Last Purchase'])

"""# Berhubung data tidak berdistribusi normal, kita coba pakai model Random Forest"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score

df.info()

#input fitur
X = df[['Age', 'Items Purchased', 'Spend per Item', 'Average Rating', 'Discount Applied', 'Days Since Last Purchase']]
y = df['Satisfaction Level']

# Training dan testing set
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(X_train.shape,y_train.shape,X_test.shape,y_test.shape)

# Membuat model Random Forest Regressor
model = RandomForestRegressor(random_state=42, n_estimators=100)

# Melatih model
model.fit(X_train, y_train)

X_test #ini buat apaan ya? wkwk

# Prediksi pada data testing
y_pred = model.predict(X_test)

# Evaluasi model
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f'Mean Squared Error: {mse}')
print(f'R^2 Score: {r2}')
#alhamdulillaah warbiyasah madagaskar

# Assuming 'model' is your trained RandomForestRegressor
example = [[35, 4, 11200, 4, 0, 15]]
satisfaction_level = model.predict(example)

# Convert the predicted value to an integer between 0 and 2
predicted_class = int(round(satisfaction_level[0]))

# Ensure the predicted class is within the valid range
predicted_class = max(0, min(predicted_class, 2))

print(f'Predicted Satisfaction Level Class: {predicted_class}')

# Assuming 'model' is your trained RandomForestRegressor
example = [[35, 4, 11200, 4, 0, 15]]
satisfaction_level = model.predict(example)

# Convert the predicted value to an integer between 0 and 2
predicted_class = int(round(satisfaction_level[0]))

# Ensure the predicted class is within the valid range
predicted_class = max(0, min(predicted_class, 2))

# Map the predicted class to the corresponding label
satisfaction_labels = ["Unsatisfied", "Neutral", "Satisfied"]
predicted_label = satisfaction_labels[predicted_class]

print(f'Predicted Satisfaction Level: {predicted_label}')

"""# Logistic Regression Model"""

from sklearn.linear_model import LogisticRegression

# Assuming X and y are already defined as in your notebook
model = LogisticRegression()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

from sklearn import metrics
accuracy = metrics.accuracy_score(y_test, y_pred)
print(f'Accuracy: {accuracy}')

# Assuming 'model' is your trained LogisticRegression model and X_test is your test data
y_pred = model.predict(X_test)

# Print the predicted satisfaction levels
print(y_pred)

example = [[28, 3, 26000, 3, 1, 10]]
satisfaction_level = model.predict(example)

# Convert the predicted value to an integer between 0 and 2
predicted_class = int(round(satisfaction_level[0]))

# Ensure the predicted class is within the valid range
predicted_class = max(0, min(predicted_class, 2))

# Map the predicted class to the corresponding label
satisfaction_labels = ["Unsatisfied", "Neutral", "Satisfied"]
predicted_label = satisfaction_labels[predicted_class]

print(f'Predicted Satisfaction Level: {predicted_label}')

"""# Model Decision Tree"""

from sklearn.tree import DecisionTreeClassifier

# Assuming X_train and y_train are already defined
model = DecisionTreeClassifier(random_state=42)  # You can adjust hyperparameters as needed

model.fit(X_train, y_train)

y_pred = model.predict(X_test)  # Assuming X_test is your test data

from sklearn import metrics
accuracy = metrics.accuracy_score(y_test, y_pred)
print(f'Accuracy: {accuracy}')

from sklearn.ensemble import RandomForestClassifier
import joblib

# Misalnya, X_train dan y_train sudah siap
model = RandomForestClassifier()
model.fit(X_train, y_train)

# Simpan model
joblib.dump(model, 'random_forest_model.pkl')

pip install streamlit

import streamlit as st
import joblib
import pandas as pd

# Load model
model = joblib.load('random_forest_model.pkl')

# Judul Aplikasi
st.title('Prediksi Analisis dengan Random Forest')

# Input pengguna
def get_user_input():
    feature1 = st.text_input('Masukkan nilai fitur 1:')
    feature2 = st.text_input('Masukkan nilai fitur 2:')
    # Tambahkan fitur lain sesuai kebutuhan

    data = {'feature1': feature1,
            'feature2': feature2}

    features = pd.DataFrame(data, index=[0])
    return features

user_input = get_user_input()

# Tampilkan input pengguna
st.write('Input pengguna:')
st.write(user_input)

# Prediksi
prediction = model.predict(user_input)
st.write('Hasil Prediksi:')
st.write(prediction)

streamlit run app.py

pip install streamlit